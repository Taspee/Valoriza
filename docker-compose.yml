version: '3.8'

services:
  web:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    depends_on:
      ollama:
        condition: service_healthy
      ollama-pull:
        condition: service_completed_successfully
    environment:
      - OLLAMA_HOST=http://ollama:11434
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s

  ollama-pull:
    image: ollama/ollama:latest
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - app-network
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: /bin/sh
    command: >
      -c "
      echo 'Waiting for Ollama server to be fully ready...';
      sleep 10;
      echo 'Checking if model exists...';
      
      if ollama list | grep -q 'llama3.2'; then
        echo 'Model llama3.2 already exists, skipping download.';
      else
        echo 'Downloading llama3.2 model... This may take a while.';
        ollama pull llama3.2;
        echo 'Model downloaded successfully!';
      fi;
      
      echo 'Verifying model...';
      ollama list;
      "

volumes:
  ollama-data:

networks:
  app-network:
    driver: bridge